
# s3_utils.py
import os
import logging
import mimetypes
import tempfile
from typing import Optional
from urllib.parse import urlparse

import boto3
from botocore.config import Config
from botocore.exceptions import (
    ClientError, NoCredentialsError, EndpointConnectionError, ProfileNotFound
)
from botocore import UNSIGNED
import httpx

# .env ×œ×¤×™×ª×•×— (×œ× ×—×•×‘×” ×‘×“×•×§×¨)
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

AWS_REGION = os.getenv("AWS_REGION")
AWS_S3_BUCKET = os.getenv("AWS_S3_BUCKET")
AWS_PROFILE = os.getenv("AWS_PROFILE")  # ×œ× ×œ×§×‘×•×¢ ×‘×¨×™×¨×ª ×ž×—×“×œ
AWS_S3_ENDPOINT_URL = os.getenv("AWS_S3_ENDPOINT_URL")
AWS_S3_ADDRESSING_STYLE = os.getenv("AWS_S3_ADDRESSING_STYLE", "path")
AWS_S3_UNSIGNED = os.getenv("AWS_S3_UNSIGNED", "false").lower() in ("1", "true", "yes")


def _make_session():
    """
    ×ž×—×–×™×¨ boto3.Session.
    ×× AWS_PROFILE ×”×•×’×“×¨ ××‘×œ ×œ× ×§×™×™× â€“ × × ×§×” ××ª ×ž×©×ª× ×™ ×”×¡×‘×™×‘×” ×•× ×‘×¦×¢ fallback ××ž×™×ª×™.
    """
    profile = os.getenv("AWS_PROFILE")
    if profile:
        try:
            return boto3.Session(profile_name=profile, region_name=AWS_REGION)
        except ProfileNotFound:
            logger.warning(
                "AWS profile '%s' not found; falling back to env/instance credentials.",
                profile,
            )
            # ðŸ”‘ ×”×›×™ ×—×©×•×‘: ×œ× ×§×•×ª ×›×“×™ ×©×‘×•×˜×• ×œ× ×™× ×¡×” ×©×•×‘ ×‘×¤×¨×•×¤×™×œ ×”×œ× ×§×™×™× ×‘×¨×§×¢
            os.environ.pop("AWS_PROFILE", None)
            os.environ.pop("AWS_DEFAULT_PROFILE", None)
    return boto3.Session(region_name=AWS_REGION)


def _make_client():
    if AWS_S3_UNSIGNED:
        cfg = Config(signature_version=UNSIGNED, s3={"addressing_style": AWS_S3_ADDRESSING_STYLE})
        mode = "UNSIGNED"
    else:
        cfg = Config(s3={"addressing_style": AWS_S3_ADDRESSING_STYLE})
        mode = "SIGNED"
    client = _make_session().client("s3", endpoint_url=AWS_S3_ENDPOINT_URL, config=cfg)
    logger.info(f"S3 client created in {mode} mode (bucket={AWS_S3_BUCKET}, region={AWS_REGION})")
    return client


_s3 = _make_client()


def refresh_client() -> None:
    global _s3
    _s3 = _make_client()
    logger.info("S3 client refreshed with current environment variables.")


def has_s3_credentials() -> bool:
    try:
        sess = _make_session()
        creds = sess.get_credentials()
        if not creds:
            return False
        fc = creds.get_frozen_credentials()
        return bool(fc and fc.access_key and fc.secret_key)
    except Exception:
        return False


def s3_download_to_path(key: str, dest_path: str) -> bool:
    if not AWS_S3_BUCKET:
        logger.error("S3: Missing AWS_S3_BUCKET env")
        return False
    os.makedirs(os.path.dirname(dest_path) or ".", exist_ok=True)
    logger.info(f"S3: downloading s3://{AWS_S3_BUCKET}/{key} -> {dest_path}")
    try:
        _s3.download_file(AWS_S3_BUCKET, key, dest_path)
        return True
    except NoCredentialsError:
        logger.error("S3 download failed: No AWS credentials available")
        return False
    except EndpointConnectionError as e:
        logger.error(f"S3 download failed: Endpoint connection error: {e}")
        return False
    except ClientError as e:
        err = e.response.get("Error", {})
        logger.error(
            f"S3 download failed for key='{key}' bucket='{AWS_S3_BUCKET}': "
            f"{err.get('Code')} - {err.get('Message')}"
        )
        return False
    except Exception as e:
        logger.exception(f"S3 download failed (unexpected): {e}")
        return False


def s3_download_to_temp(key: str, suffix: Optional[str] = None) -> Optional[str]:
    ext = suffix or os.path.splitext(key)[1] or ".bin"
    try:
        fd, tmp_path = tempfile.mkstemp(suffix=ext)
        os.close(fd)
        ok = s3_download_to_path(key, tmp_path)
        return tmp_path if ok else None
    except Exception as e:
        logger.exception(f"S3 temp download failed: {e}")
        return None


def s3_upload_file(local_path: str, key: str, extra_args: Optional[dict] = None) -> bool:
    if not AWS_S3_BUCKET:
        logger.error("S3: Missing AWS_S3_BUCKET env")
        return False
    if not os.path.isfile(local_path):
        logger.error(f"S3 upload failed: local file not found: {local_path}")
        return False
    if not has_s3_credentials():
        logger.warning("S3 upload skipped: no credentials available in environment/instance.")
        return False

    if extra_args is None:
        extra_args = {}
    if "ContentType" not in extra_args:
        ctype, _ = mimetypes.guess_type(local_path)
        extra_args["ContentType"] = ctype or "application/octet-stream"

    logger.info(f"S3: uploading {local_path} -> s3://{AWS_S3_BUCKET}/{key}")
    try:
        _s3.upload_file(local_path, AWS_S3_BUCKET, key, ExtraArgs=extra_args)
        return True
    except NoCredentialsError:
        logger.error("S3 upload failed: No AWS credentials available")
        return False
    except EndpointConnectionError as e:
        logger.error(f"S3 upload failed: Endpoint connection error: {e}")
        return False
    except ClientError as e:
        err = e.response.get("Error", {})
        logger.error(
            f"S3 upload failed for key='{key}' bucket='{AWS_S3_BUCKET}': "
            f"{err.get('Code')} - {err.get('Message')}"
        )
        return False
    except Exception as e:
        logger.exception(f"S3 upload failed (unexpected): {e}")
        return False


def s3_delete_object(key: str) -> bool:
    if not AWS_S3_BUCKET:
        logger.error("S3: Missing AWS_S3_BUCKET env")
        return False
    if not has_s3_credentials():
        logger.warning("S3 delete skipped: no credentials available.")
        return False
    try:
        _s3.delete_object(Bucket=AWS_S3_BUCKET, Key=key)
        logger.info(f"S3: deleted s3://{AWS_S3_BUCKET}/{key}")
        return True
    except NoCredentialsError:
        logger.error("S3 delete failed: No AWS credentials available")
        return False
    except EndpointConnectionError as e:
        logger.error(f"S3 delete failed: Endpoint connection error: {e}")
        return False
    except ClientError as e:
        err = e.response.get("Error", {})
        logger.error(
            f"S3 delete failed for key='{key}' bucket='{AWS_S3_BUCKET}': "
            f"{err.get('Code')} - {err.get('Message')}"
        )
        return False
    except Exception as e:
        logger.exception(f"S3 delete failed (unexpected): {e}")
        return False


def s3_presign_get_url(key: str, expires_in: int = 3600) -> Optional[str]:
    if not AWS_S3_BUCKET:
        logger.error("S3: Missing AWS_S3_BUCKET env")
        return None
    if not has_s3_credentials():
        logger.info("Skipping presign: no AWS credentials available.")
        return None
    try:
        url = _s3.generate_presigned_url(
            "get_object",
            Params={"Bucket": AWS_S3_BUCKET, "Key": key},
            ExpiresIn=expires_in,
        )
        return url
    except Exception as e:
        logger.exception(f"S3 presign get url failed: {e}")
        return None


def s3_or_http_download(ref: str, dest_path: str) -> bool:
    """
    ×”×•×¨×“×” ×ž××•×—×“×ª:
      - http(s) ×ž×œ× (×›×•×œ×œ presigned) -> HTTP
      - s3://bucket/key               -> S3
      - key ×œ×œ× scheme                -> ×ž×ª×•×š ×”×‘×§×˜ ×©×‘-ENV
    """
    try:
        parsed = urlparse(ref)
        scheme = (parsed.scheme or "").lower()

        if scheme in ("http", "https"):
            with httpx.stream("GET", ref, timeout=60.0) as r:
                if r.status_code != 200:
                    logger.error(f"HTTP download failed: {r.status_code} - {ref}")
                    return False
                os.makedirs(os.path.dirname(dest_path) or ".", exist_ok=True)
                with open(dest_path, "wb") as f:
                    for chunk in r.iter_bytes():
                        f.write(chunk)
            return True

        if scheme == "s3":
            bucket = parsed.netloc
            key = parsed.path.lstrip("/")
            if not bucket or not key:
                logger.error(f"Invalid s3 URL: {ref}")
                return False
            try:
                os.makedirs(os.path.dirname(dest_path) or ".", exist_ok=True)
                _s3.download_file(bucket, key, dest_path)
                return True
            except Exception as e:
                logger.exception(f"S3 download (s3://...) failed: {e}")
                return False

        # ××—×¨×ª: treat as key ×‘×‘×§×˜ ×©×”×•×’×“×¨ ×‘-ENV
        return s3_download_to_path(ref, dest_path)

    except Exception as e:
        logger.exception(f"s3_or_http_download failed for ref='{ref}': {e}")
        return False













# s3_utils.py

# import os
# import logging
# import mimetypes
# import tempfile
# from typing import Optional

# import boto3
# from botocore.config import Config
# from botocore.exceptions import (
#     ClientError, NoCredentialsError, EndpointConnectionError, ProfileNotFound
# )

# try:
#     from dotenv import load_dotenv  # type: ignore
#     load_dotenv()
# except Exception:
#     pass

# logger = logging.getLogger(__name__)
# logger.setLevel(logging.INFO)

# AWS_REGION = os.getenv("AWS_REGION")
# AWS_S3_BUCKET = os.getenv("AWS_S3_BUCKET")
# AWS_PROFILE = os.getenv("AWS_PROFILE")  # ××œ ×ª×§×‘×¢ ×‘×¨×™×¨×ª ×ž×—×“×œ!
# AWS_S3_ENDPOINT_URL = os.getenv("AWS_S3_ENDPOINT_URL")
# AWS_S3_ADDRESSING_STYLE = os.getenv("AWS_S3_ADDRESSING_STYLE", "path")
# AWS_S3_UNSIGNED = os.getenv("AWS_S3_UNSIGNED", "false").lower() in ("1", "true", "yes")  # ×—×“×©

# def _make_session():
#     # ×× ×‘×™×§×©×• ×¤×¨×•×¤×™×œ ××‘×œ ××™×Ÿ ×›×–×”, × ×–×”×™×¨ ×•× ×™×¤×•×œ ×—×–×¨×”
#     if AWS_PROFILE:
#         try:
#             return boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION)
#         except ProfileNotFound:
#             logger.warning(
#                 "AWS profile '%s' not found; falling back to default env/instance credentials.",
#                 AWS_PROFILE
#             )
#     return boto3.Session(region_name=AWS_REGION)

# def _make_client():
#     # ×ª×ž×™×›×” ×‘×’×™×©×” ×× ×•× ×™×ž×™×ª ×œ××•×‘×™×™×§×˜×™× ×¦×™×‘×•×¨×™×™× (×œ×ž×©×œ MinIO/×‘×§×˜ ×¤×•×ž×‘×™)
#     if AWS_S3_UNSIGNED:
#         from botocore import UNSIGNED
#         cfg = Config(signature_version=UNSIGNED, s3={'addressing_style': AWS_S3_ADDRESSING_STYLE})
#     else:
#         cfg = Config(s3={'addressing_style': AWS_S3_ADDRESSING_STYLE})
#     return _make_session().client("s3", endpoint_url=AWS_S3_ENDPOINT_URL, config=cfg)

# _s3 = _make_client()



# def refresh_client() -> None:
#     """×œ×ž×§×¨×” ×©×©×™× ×™×ª ENV ×‘×–×ž×Ÿ ×¨×™×¦×” ×•×¨×•×¦×” ×œ×¨×¢× ×Ÿ ××ª ×”×œ×§×•×—."""
#     global _s3
#     _s3 = _make_client()
#     logger.info("S3 client refreshed with current environment variables.")


# def s3_download_to_path(key: str, dest_path: str) -> bool:
#     """
#     ×ž×•×¨×™×“ ××•×‘×™×™×§×˜ S3 ×œ× ×ª×™×‘ ×ž×§×•×ž×™.
#     :param key: ×”×ž×¤×ª×— ×”×ž×“×•×™×§ ×‘-S3 (case-sensitive), ×œ×ž×©×œ 'beatles.jpeg' ××• 'user/original/uid.jpg'
#     :param dest_path: × ×ª×™×‘ ×§×•×‘×¥ ×ž×§×•×ž×™ ×œ×©×ž×™×¨×”
#     :return: True/False
#     """
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return False

#     os.makedirs(os.path.dirname(dest_path) or ".", exist_ok=True)
#     logger.info(f"S3: downloading s3://{AWS_S3_BUCKET}/{key} -> {dest_path}")

#     try:
#         _s3.download_file(AWS_S3_BUCKET, key, dest_path)
#         return True

#     except NoCredentialsError:
#         logger.error("S3 download failed: No AWS credentials available (set AWS_PROFILE "
#                      "or AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY)")
#         return False

#     except EndpointConnectionError as e:
#         logger.error(f"S3 download failed: Endpoint connection error: {e}")
#         return False

#     except ClientError as e:
#         err = e.response.get("Error", {})
#         code = err.get("Code")
#         msg = err.get("Message")
#         logger.error(f"S3 download failed for key='{key}' bucket='{AWS_S3_BUCKET}': {code} - {msg}")
#         return False

#     except Exception as e:
#         logger.exception(f"S3 download failed (unexpected): {e}")
#         return False


# def s3_download_to_temp(key: str, suffix: Optional[str] = None) -> Optional[str]:
#     """
#     ×ž×•×¨×™×“ ××•×‘×™×™×§×˜ ×œÖ¾temp file ×•×ž×—×–×™×¨ ××ª ×”× ×ª×™×‘ (××• None ×× ×›×©×œ).
#     :param key: S3 key
#     :param suffix: ×¡×™×•×ž×ª ×¨×¦×•×™×” ×œ×§×•×‘×¥ ×”×–×ž× ×™ (×× None ×™×™×œ×§×— ×ž×”-key, ×•×× ××™×Ÿ â€” .bin)
#     """
#     ext = suffix or os.path.splitext(key)[1] or ".bin"
#     try:
#         fd, tmp_path = tempfile.mkstemp(suffix=ext)
#         os.close(fd)
#         ok = s3_download_to_path(key, tmp_path)
#         return tmp_path if ok else None
#     except Exception as e:
#         logger.exception(f"S3 temp download failed: {e}")
#         return None


# def s3_upload_file(local_path: str, key: str, extra_args: Optional[dict] = None) -> bool:
#     """
#     ×ž×¢×œ×” ×§×•×‘×¥ ×ž×§×•×ž×™ ×œ-S3 ×ª×—×ª key × ×ª×•×Ÿ.
#     :param local_path: × ×ª×™×‘ ×ž×§×•×ž×™ ×œ×§×•×‘×¥
#     :param key: ×”-key ×‘-S3
#     :param extra_args: ExtraArgs ×œ-boto3 (×œ×ž×©×œ {'Metadata': {...}, 'ContentType': 'image/jpeg'})
#     :return: True/False
#     """
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return False

#     if not os.path.isfile(local_path):
#         logger.error(f"S3 upload failed: local file not found: {local_path}")
#         return False

#     # ×“××’ ×œ-ContentType ×¡×‘×™×¨ ×× ×œ× ×¡×•×¤×§
#     if extra_args is None:
#         extra_args = {}
#     if "ContentType" not in extra_args:
#         ctype, _ = mimetypes.guess_type(local_path)
#         extra_args["ContentType"] = ctype or "application/octet-stream"

#     logger.info(f"S3: uploading {local_path} -> s3://{AWS_S3_BUCKET}/{key}")
#     try:
#         _s3.upload_file(local_path, AWS_S3_BUCKET, key, ExtraArgs=extra_args)
#         return True

#     except NoCredentialsError:
#         logger.error("S3 upload failed: No AWS credentials available (set AWS_PROFILE "
#                      "or AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY)")
#         return False

#     except EndpointConnectionError as e:
#         logger.error(f"S3 upload failed: Endpoint connection error: {e}")
#         return False

#     except ClientError as e:
#         err = e.response.get("Error", {})
#         code = err.get("Code")
#         msg = err.get("Message")
#         logger.error(f"S3 upload failed for key='{key}' bucket='{AWS_S3_BUCKET}': {code} - {msg}")
#         return False

#     except Exception as e:
#         logger.exception(f"S3 upload failed (unexpected): {e}")
#         return False


# def s3_delete_object(key: str) -> bool:
#     """×ž×•×—×§ ××•×‘×™×™×§×˜ ×žÖ¾S3 ×œ×¤×™ key."""
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return False
#     try:
#         _s3.delete_object(Bucket=AWS_S3_BUCKET, Key=key)
#         logger.info(f"S3: deleted s3://{AWS_S3_BUCKET}/{key}")
#         return True
#     except NoCredentialsError:
#         logger.error("S3 delete failed: No AWS credentials available")
#         return False
#     except EndpointConnectionError as e:
#         logger.error(f"S3 delete failed: Endpoint connection error: {e}")
#         return False
#     except ClientError as e:
#         err = e.response.get("Error", {})
#         logger.error(f"S3 delete failed for key='{key}' bucket='{AWS_S3_BUCKET}': {err.get('Code')} - {err.get('Message')}")
#         return False
#     except Exception as e:
#         logger.exception(f"S3 delete failed (unexpected): {e}")
#         return False


# def s3_presign_get_url(key: str, expires_in: int = 3600) -> Optional[str]:
#     """
#     ×ž×—×–×™×¨ URL ×—×ª×•× ×œ×”×•×¨×“×ª GET ×©×ª×§×£ expires_in ×©× ×™×•×ª.
#     :param key: S3 key
#     :param expires_in: ×ª×•×§×£ ×‘×©× ×™×•×ª (×‘×¨×™×¨×ª ×ž×—×“×œ: ×©×¢×”)
#     """
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return None
#     try:
#         url = _s3.generate_presigned_url(
#             "get_object",
#             Params={"Bucket": AWS_S3_BUCKET, "Key": key},
#             ExpiresIn=expires_in
#         )
#         return url
#     except Exception as e:
#         logger.exception(f"S3 presign get url failed: {e}")
#         return None


# def has_s3_credentials() -> bool:
#     """
#     True ×× ×™×© ×œ×§×¨×™××” ×œ-S3 ×§×¨×“× ×¦'×™××œ×¡ ×–×ž×™× ×™× (env/×§×‘×¦×™×/metadata/STS).
#     """
#     try:
#         sess = _make_session()
#         creds = sess.get_credentials()
#         if not creds:
#             return False
#         creds = creds.get_frozen_credentials()
#         return bool(creds and creds.access_key and creds.secret_key)
#     except Exception:
#         return False




# # s3_utils.py
# import os
# import logging
# import mimetypes
# from typing import Optional

# import boto3
# from botocore.config import Config
# from botocore.exceptions import ClientError, NoCredentialsError, EndpointConnectionError

# # ×˜×¢×™× ×ª .env ×œ×¤×™×ª×•×— (×¨×©×•×ª; ×™×ª×¢×œ× ×× python-dotenv ×œ× ×ž×•×ª×§×Ÿ)
# try:
#     from dotenv import load_dotenv  # type: ignore
#     load_dotenv()
# except Exception:
#     pass

# logger = logging.getLogger(__name__)
# logger.setLevel(logging.INFO)

# # -------- ×ž×©×ª× ×™ ×¡×‘×™×‘×” --------
# AWS_REGION = os.getenv("AWS_REGION")                 # ×œ×ž×©×œ: eu-west-1
# AWS_S3_BUCKET = os.getenv("AWS_S3_BUCKET")           # ×œ×ž×©×œ: tameer-yolo-images
# AWS_PROFILE = os.getenv("AWS_PROFILE")               # ××•×¤×¦×™×•× ×œ×™ (×œ×©×™×ž×•×© ×‘×¤×¨×•×¤×™×œ CLI ×œ×•×§××œ×™)
# AWS_S3_ENDPOINT_URL = os.getenv("AWS_S3_ENDPOINT_URL")  # ××•×¤×¦×™×•× ×œ×™ (MinIO/LocalStack ×•×›×“×³)
# AWS_S3_ADDRESSING_STYLE = os.getenv("AWS_S3_ADDRESSING_STYLE", "path")  # 'path' ××• 'virtual'
# # --------------------------------

# def _make_session():
#     if AWS_PROFILE:
#         return boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION)
#     return boto3.Session(region_name=AWS_REGION)

# def _make_client():
#     cfg = Config(s3={'addressing_style': AWS_S3_ADDRESSING_STYLE})
#     return _make_session().client("s3", endpoint_url=AWS_S3_ENDPOINT_URL, config=cfg)

# # × ×™×¦×•×¨ ×œ×§×•×— ×¤×¢× ××—×ª
# _s3 = _make_client()

# def refresh_client() -> None:
#     """×œ×ž×§×¨×” ×©×©×™× ×™×ª ENV ×‘×–×ž×Ÿ ×¨×™×¦×” ×•×¨×•×¦×” ×œ×¨×¢× ×Ÿ ××ª ×”×œ×§×•×—."""
#     global _s3
#     _s3 = _make_client()
#     logger.info("S3 client refreshed with current environment variables.")

# def s3_download_to_path(key: str, dest_path: str) -> bool:
#     """
#     ×ž×•×¨×™×“ ××•×‘×™×™×§×˜ S3 ×œ× ×ª×™×‘ ×ž×§×•×ž×™.
#     :param key: ×”×ž×¤×ª×— ×”×ž×“×•×™×§ ×‘-S3 (case-sensitive), ×œ×ž×©×œ 'beatles.jpeg' ××• 'user/original/uid.jpg'
#     :param dest_path: × ×ª×™×‘ ×§×•×‘×¥ ×ž×§×•×ž×™ ×œ×©×ž×™×¨×”
#     :return: True/False
#     """
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return False

#     os.makedirs(os.path.dirname(dest_path) or ".", exist_ok=True)
#     logger.info(f"S3: downloading s3://{AWS_S3_BUCKET}/{key} -> {dest_path}")

#     try:
#         _s3.download_file(AWS_S3_BUCKET, key, dest_path)
#         return True

#     except NoCredentialsError:
#         logger.error("S3 download failed: No AWS credentials available (set AWS_PROFILE "
#                      "or AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY)")
#         return False

#     except EndpointConnectionError as e:
#         logger.error(f"S3 download failed: Endpoint connection error: {e}")
#         return False

#     except ClientError as e:
#         err = e.response.get("Error", {})
#         code = err.get("Code")
#         msg = err.get("Message")
#         logger.error(f"S3 download failed for key='{key}' bucket='{AWS_S3_BUCKET}': {code} - {msg}")
#         return False

#     except Exception as e:
#         logger.exception(f"S3 download failed (unexpected): {e}")
#         return False

# def s3_upload_file(local_path: str, key: str, extra_args: Optional[dict] = None) -> bool:
#     """
#     ×ž×¢×œ×” ×§×•×‘×¥ ×ž×§×•×ž×™ ×œ-S3 ×ª×—×ª key × ×ª×•×Ÿ.
#     :param local_path: × ×ª×™×‘ ×ž×§×•×ž×™ ×œ×§×•×‘×¥
#     :param key: ×”-key ×‘-S3
#     :param extra_args: ExtraArgs ×œ-boto3 (×œ×ž×©×œ {'Metadata': {...}, 'ContentType': 'image/jpeg'})
#     :return: True/False
#     """
#     if not AWS_S3_BUCKET:
#         logger.error("S3: Missing AWS_S3_BUCKET env")
#         return False

#     if not os.path.isfile(local_path):
#         logger.error(f"S3 upload failed: local file not found: {local_path}")
#         return False

#     # ×“××’ ×œ-ContentType ×¡×‘×™×¨ ×× ×œ× ×¡×•×¤×§
#     if extra_args is None:
#         extra_args = {}
#     if "ContentType" not in extra_args:
#         ctype, _ = mimetypes.guess_type(local_path)
#         extra_args["ContentType"] = ctype or "application/octet-stream"

#     logger.info(f"S3: uploading {local_path} -> s3://{AWS_S3_BUCKET}/{key}")
#     try:
#         _s3.upload_file(local_path, AWS_S3_BUCKET, key, ExtraArgs=extra_args)
#         return True

#     except NoCredentialsError:
#         logger.error("S3 upload failed: No AWS credentials available (set AWS_PROFILE "
#                      "or AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY)")
#         return False

#     except EndpointConnectionError as e:
#         logger.error(f"S3 upload failed: Endpoint connection error: {e}")
#         return False

#     except ClientError as e:
#         err = e.response.get("Error", {})
#         code = err.get("Code")
#         msg = err.get("Message")
#         logger.error(f"S3 upload failed for key='{key}' bucket='{AWS_S3_BUCKET}': {code} - {msg}")
#         return False

#     except Exception as e:
#         logger.exception(f"S3 upload failed (unexpected): {e}")
#         return False
    


#############################################################################3
# import os
# import logging
# import boto3
# from botocore.exceptions import ClientError

# AWS_REGION = os.getenv("AWS_REGION")
# AWS_S3_BUCKET = os.getenv("AWS_S3_BUCKET")

# # × ×™×¦×•×¨ ×œ×§×•×— ×¤×¢× ××—×ª (×ž×©×ª×ž×© ×‘×”×¨×©××•×ª IAM ×©×œ ×”×ž×¢×¨×›×ª/×§×•× ×˜×™×™× ×¨)
# _s3 = boto3.client("s3", region_name=AWS_REGION) if AWS_REGION else boto3.client("s3")

# def s3_download_to_path(key: str, dest_path: str) -> bool:
#     """×ž×•×¨×™×“ ××•×‘×™×™×§×˜ S3 ×œ× ×ª×™×‘ ×ž×§×•×ž×™"""
#     if not AWS_S3_BUCKET:
#         logging.error("Missing AWS_S3_BUCKET env")
#         return False
#     os.makedirs(os.path.dirname(dest_path), exist_ok=True)
#     try:
#         _s3.download_file(AWS_S3_BUCKET, key, dest_path)
#         return True
#     except ClientError as e:
#         logging.error(f"S3 download failed: {e}")
#         return False

# def s3_upload_file(local_path: str, key: str, extra_args: dict | None = None) -> bool:
#     """×ž×¢×œ×” ×§×•×‘×¥ ×ž×§×•×ž×™ ×œ-S3 ×ª×—×ª key × ×ª×•×Ÿ"""
#     if not AWS_S3_BUCKET:
#         logging.error("Missing AWS_S3_BUCKET env")
#         return False
#     try:
#         if extra_args:
#             _s3.upload_file(local_path, AWS_S3_BUCKET, key, ExtraArgs=extra_args)
#         else:
#             _s3.upload_file(local_path, AWS_S3_BUCKET, key)
#         return True
#     except ClientError as e:
#         logging.error(f"S3 upload failed: {e}")
#         return False
